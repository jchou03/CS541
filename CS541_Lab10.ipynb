{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS541: Applied Machine Learning, Fall 2024, Lab 10\n",
        "\n",
        "Lab 10 is an exercise that explores Reinforcement Learning. In reinforcement learning, an agent learns to make decisions by interacting with an environment, it is used in robotics and other decision-making settings. Reinforcement learning works by having an agent interact with an environment and through trial-and-error is rewarded or punished based on certain actions. Based on the modeling on the environment the action can learn from it's environment but sometimes this may need to be adjusted to help the agent better learn.\n",
        "\n",
        "**Lab Grading**\n",
        "\n",
        "Labs are hands-on exercises designed to provide guided experience in key concepts through this class.  You are graded based on in-lab participation (not correctness), and are not required to submit your lab if you attend in-person.  *Make sure you fill out the attendence form before leaving class*.\n",
        "\n",
        "For students who miss a lab, you can submit a make-up lab on gradescope by the Friday directly following the lab for partial credit.  Please see the syllabus for the lab grading policy."
      ],
      "metadata": {
        "id": "t1dLwqvvHC9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fun references for RL and Q Learning: http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture14.pdf\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3EEWHMbNufuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt-get install -y xvfb ffmpeg x11-utils\n",
        "!pip install gym pyvirtualdisplay PyOpenGL PyOpenGL-accelerate\n",
        "!pip install xvfbwrapper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7nZDqq2HZx5",
        "outputId": "933c04a5-6308-43e1-dc17-cc0c045c35b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,626 B 0%] [Waiting for headers] [W\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connecte\u001b[0m\r                                                                                                    \rGet:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [2 InRelease 14.2 kB/129 kB 11%] [Waiting for headers] [Waiting for headers\u001b[0m\r                                                                                                    \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [2 InRelease 14.2 kB/129 kB 11%] [Waiting for headers] [Connected to ppa.la\u001b[0m\r                                                                                                    \rGet:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [2 InRelease 14.2 kB/129 kB 11%] [Connected to ppa.launchpadcontent.net (18\u001b[0m\r                                                                                                    \rHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,105 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,605 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,665 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,434 kB]\n",
            "Fetched 15.2 MB in 5s (2,858 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "52 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 libxtst6 libxxf86dga1 x11-xkb-utils xfonts-base\n",
            "  xfonts-encodings xfonts-utils xserver-common\n",
            "Suggested packages:\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 libxtst6 libxxf86dga1 x11-utils x11-xkb-utils xfonts-base\n",
            "  xfonts-encodings xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 12 newly installed, 0 to remove and 52 not upgraded.\n",
            "Need to get 8,046 kB of archives.\n",
            "After this operation, 12.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.12 [864 kB]\n",
            "Fetched 8,046 kB in 0s (33.0 MB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 123623 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../01-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../02-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../03-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../04-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../05-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../06-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../07-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../08-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../09-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../10-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../11-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Requirement already satisfied: PyOpenGL in /usr/local/lib/python3.10/dist-packages (3.1.7)\n",
            "Collecting PyOpenGL-accelerate\n",
            "  Downloading PyOpenGL_accelerate-3.1.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (789 bytes)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (3.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Downloading PyOpenGL_accelerate-3.1.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyvirtualdisplay, PyOpenGL-accelerate\n",
            "Successfully installed PyOpenGL-accelerate-3.1.7 pyvirtualdisplay-3.0\n",
            "Collecting xvfbwrapper\n",
            "  Downloading xvfbwrapper-0.2.9.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: xvfbwrapper\n",
            "  Building wheel for xvfbwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xvfbwrapper: filename=xvfbwrapper-0.2.9-py3-none-any.whl size=5010 sha256=8bfa8e5745f097ee03db996d1ff271e0a839fbee673145f1f083cf11d7209b6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/10/7d/2b7fdffccf837f7d5425931575fbee9caebe2c190931f9058b\n",
            "Successfully built xvfbwrapper\n",
            "Installing collected packages: xvfbwrapper\n",
            "Successfully installed xvfbwrapper-0.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEvn9FApG_Nx",
        "outputId": "51a1a34a-8721-4d86-d28b-d70cb7342b78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7d01b26bab00>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import clear_output\n",
        "import imageio\n",
        "import base64\n",
        "import math\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "89-s1xk9L0cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here we will go about implementing the MountainCar example from OpenAI's gym library\n",
        "https://www.gymlibrary.dev/environments/classic_control/mountain_car/"
      ],
      "metadata": {
        "id": "1LR3_oHZk926"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "state, info = env.reset()\n",
        "print('len(state)')\n",
        "print((state))\n",
        "print(info)\n",
        "\n",
        "LEARNING_RATE = 0.1\n",
        "DISCOUNT = 0.95\n",
        "EPISODES = 10000\n",
        "\n",
        "SHOW_EVERY = 200\n",
        "\n",
        "\n",
        "# Use this to represent the bins for each axis\n",
        "DISCRETE_OS_SIZE = [18] * len(env.observation_space.high)\n",
        "\n",
        "# This is calculated by subtracting the (high and lowest values for observation space) and dividing that by the discrete_os_size we defined above\n",
        "discrete_os_win_size =\n",
        "\n",
        "# We create the q_table by using the uniform generator from numpy\n",
        "# We use the low value as -2 and the high value as 0, the size would be the discrete_os_size we defined above plus the action space number\n",
        "q_table = np.randon.uniform(,,size=( + [env.action_space.n]))\n",
        "\n",
        "print('q_table.shape')\n",
        "print(q_table.shape)\n",
        "def get_discrete_state(state):\n",
        "    #To discretize the state, we use the (state and subtract it from the lowest observation space value)\n",
        "    # and we divide this output by the discrete_os_win_size we defined above\n",
        "    discrete_state =\n",
        "    return tuple(discrete_state.astype(int))\n",
        "\n",
        "\n",
        "for episode in range(EPISODES):\n",
        "    if episode % SHOW_EVERY == 0:\n",
        "        render = True\n",
        "    else:\n",
        "        render = False\n",
        "\n",
        "    discrete_state = get_discrete_state(env.reset())\n",
        "    print('discrete_state')\n",
        "    print(discrete_state)\n",
        "    frames = []\n",
        "    done = False\n",
        "    while not done:\n",
        "        # Here we get the argmax of the q-table value at the discrete_state\n",
        "        action =\n",
        "        new_state, reward, done, _ = env.step(action)\n",
        "        # Call the discrete_state function we defined above and pass the new_state we obtained\n",
        "        new_discrete_state =\n",
        "        if render:\n",
        "            frames.append(env.render(mode=\"rgb_array\"))\n",
        "\n",
        "        if not done:\n",
        "            # Here we get the max of the q-table value at the new_discrete_state\n",
        "            max_future_q =\n",
        "            current_q = q_table[discrete_state + (action, )]\n",
        "\n",
        "            # Here we calculate the new q_value, in this instance we use ((1 - learning rate) multiplied by the current q value)\n",
        "            # we then add this result to the (learning rate multipled by (reward plus the discount value multipled by the max_future_q))\n",
        "            new_q =\n",
        "            q_table[discrete_state + (action, )] = new_q\n",
        "        elif new_state[0] >= env.goal_position:\n",
        "            print(f\"Congratulation! We reached to the goal! Episode: {episode}\")\n",
        "            q_table[discrete_state + (action, )] = 0\n",
        "\n",
        "        # We set the discrete state to the new discrete state\n",
        "        discrete_state =\n",
        "    if render:\n",
        "        print(frames[0].shape)\n",
        "        #We save the result as a gif, which we can view as it is saved in our Google Colab folder\n",
        "        imageio.mimsave(f'./{episode}.gif', frames, fps=40)\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TXljoJF2s3Z8",
        "outputId": "f304e782-053a-489c-c23e-f47af9d94e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(state)\n",
            "-0.44478637\n",
            "0.0\n",
            "env.observation_space.high\n",
            "[0.6  0.07]\n",
            "DISCRETE_OS_SIZE\n",
            "[18, 18]\n",
            "env.action_space.n\n",
            "3\n",
            "Discrete(3)\n",
            "q_table.shape\n",
            "(18, 18, 3)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "(400, 600, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imageio/plugins/pillow.py:409: DeprecationWarning: The keyword `fps` is no longer supported. Use `duration`(in ms) instead, e.g. `fps=50` == `duration=20` (1000 * 1/50).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(6, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n",
            "discrete_state\n",
            "(7, 9)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-d7d7452ad066>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Here we get the max of the q-table value at the discrete_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiscrete_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mnew_discrete_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_discrete_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \"\"\"\n\u001b[1;32m     59\u001b[0m         observation, reward, terminated, truncated, info = step_api_compatibility(\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     41\u001b[0m             )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \"\"\"Steps through the environment, returning 5 or 4 items depending on `new_step_api`.\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's teach a machine to balance a cartpole\n",
        "\n",
        "https://www.gymlibrary.dev/environments/classic_control/cart_pole/\n",
        "\n",
        "<img src=\"https://www.gymlibrary.dev/_images/cart_pole.gif\">\n",
        "\n"
      ],
      "metadata": {
        "id": "7DlubmKaXqUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1')"
      ],
      "metadata": {
        "id": "EnVibeFvJifL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60e75fe-85b7-409d-f7c9-af002d5002a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We need to discretize the state space.\n",
        "\n",
        "Which means:\n",
        "\n",
        "Make a list of all possible states with possible values. Since angles can be continous and range from -infinity to +infinity, we need to define some coarse values to make it into a finite list.\n",
        "\n",
        "The funtion `discretize_state(observation, state_space)` does that for you.\n",
        "\n",
        "It takes in the environment (which is the cartpole simulator) and the current state, defined by 4 parameters:\n",
        "1. Cart Position: ranges from -4.8 to 4.8\n",
        "2. Cart Velocity: ranges from -Inf to Inf\n",
        "3. Pole Angle: ranges from  -0.418 rad (-24°) to 0.418 rad (24°)\n",
        "4. Pole Angular Velocity: -Inf to Inf\n",
        "\n",
        "Since we cannot have infinite values, we cap it to some min and max value.\n",
        "\n",
        "`discretize_state(observation, state_space)` will take in the 4 state space values, and turn it into an index in a flattened list indicating that state.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NHguxsdyz2ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Discretize the state space\n",
        "# Example discretization: 30 bins for each of the 4 state values\n",
        "state_space = []\n",
        "#Get the product of the state_space values\n",
        "state_space_size =\n",
        "\n",
        "print(f\"Possible number of states : {state_space_size}\")\n",
        "\n",
        "\n",
        "# Define a simple method to discretize continuous state space\n",
        "def discretize_state(observation, state_space):\n",
        "\n",
        "    # For the upper_bounds let position 0 be the first highest value in the observation_space\n",
        "    # For the upper_bounds let position 1 be the third highest value in the observation_space\n",
        "    upper_bounds = [, 0.5, , math.radians(50)]\n",
        "    # For the lower bound let position 0 be the first lowest value in the observation_space\n",
        "    # For the lower bound let position 1 be the third lowest value in the observation_space\n",
        "    lower_bounds = [, -0.5, , -math.radians(50)]\n",
        "\n",
        "    # Let the ratios be the (observation at position i plus the absolute lower_bounds value at position i)\n",
        "    # We devide that by the (upper bounds at position i minus the lower bounds at position i)\n",
        "    ratios = [( )) / () for i in range(len(observation))]\n",
        "    new_observation = [int(round((state_space[i] - 1) * ratios[i])) for i in range(len(observation))]\n",
        "    #print(new_observation)\n",
        "\n",
        "    # For the new observation we will get the minimum of the ( (state space at position i minus 1), max(0, new_observation[i]) )\n",
        "    new_observation = [min(, max(0, new_observation[i])) for i in range(len(observation))]\n",
        "    #print(new_observation)\n",
        "    return tuple(new_observation)"
      ],
      "metadata": {
        "id": "Px78VhBTz4Vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f6aac4-f85d-43d0-f111-17d02a278099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Possible number of states : 810000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset() # gives the initial start state."
      ],
      "metadata": {
        "id": "QkdODpmuMjuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b955a4-c944-4bdc-f92f-916da2274a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.03523269,  0.04652291,  0.0069966 , -0.00658871], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's train the Q-learning agent.\n",
        "\n",
        "Play with the **`exploration_rate`, `exploration_decay_rate`**, and tweak the **`reward`** and see how the behavior changes.\n",
        "\n",
        "Sometimes, tricks as simple as training for longer (change **`episodes`**) can make a huge difference."
      ],
      "metadata": {
        "id": "PcHsPSuqnq5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, action_space, state_space, learning_rate=0.1, discount_factor=0.95, exploration_rate=1.0, exploration_decay_rate=0.9999995):\n",
        "        #Assign the corresponding args to the class instance variables\n",
        "        self.action_space =\n",
        "        self.state_space =\n",
        "        self.learning_rate =\n",
        "        self.discount_factor =\n",
        "        self.exploration_rate =\n",
        "        self.exploration_decay_rate =\n",
        "        # We define the q-table to a numpy array with zeros with number of rows being the state_space arg and the columns being the action_space\n",
        "        self.q_table =\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.uniform(0, 1) < self.exploration_rate:\n",
        "            #Randomly choose a element from the action_space using numpy\n",
        "            return\n",
        "        else:\n",
        "            # Using numpy to get the argmax of the q-table at state position\n",
        "            return\n",
        "\n",
        "    def learn(self, state, action, reward, next_state, done):\n",
        "        # Get the element from the q-table at the row at the state position and the column at the action position\n",
        "        predict =\n",
        "        # The target is -0.5 if done else it is the reward plus the discount_factor multiplied by the np max value of the q-table at the next_state\n",
        "        target = -0.5 if done else\n",
        "        # for the q-table value at the row at the state position and the column at the action position, we add that to the learning-rate multiplied by the (target minus the predict value)\n",
        "        self.q_table[state, action] +=\n",
        "        if not done:\n",
        "            self.exploration_rate *= self.exploration_decay_rate"
      ],
      "metadata": {
        "id": "Grfogjo0Jg4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = QLearningAgent(env.action_space.n, state_space_size, exploration_rate=1.0, exploration_decay_rate=0.999995)\n",
        "\n",
        "def train_agent(episodes=40000):\n",
        "    for episode in range(episodes):\n",
        "        current_state = discretize_state(env.reset(), state_space)\n",
        "        current_state = np.prod(current_state)\n",
        "        #print(\"Current state\", current_state)\n",
        "        done = False\n",
        "        count=0\n",
        "        while not done:\n",
        "            count+=1\n",
        "            action = agent.choose_action(current_state)\n",
        "\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            ## Example of other things to tweak the reward\n",
        "            # angle = next_state[2]\n",
        "\n",
        "            next_state_discrete = discretize_state(next_state, state_space)\n",
        "            next_state_discrete_ind = np.prod(next_state_discrete)\n",
        "\n",
        "            agent.learn(current_state, action, reward, next_state_discrete_ind, done) # tweak the reward input here\n",
        "            current_state = next_state_discrete_ind\n",
        "\n",
        "        if episode % 100 == 0:\n",
        "            print(f\"Episode: {episode}, Exploration rate: {agent.exploration_rate}\")\n",
        "\n",
        "train_agent()"
      ],
      "metadata": {
        "id": "P4VDlk-4JnCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089f1896-5855-433c-a1c5-059ba6c2bdd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(810000, 2)\n",
            "Episode: 0, Exploration rate: 0.9999600006999928\n",
            "Episode: 100, Exploration rate: 0.9887289710561517\n",
            "Episode: 200, Exploration rate: 0.9787196375923463\n",
            "Episode: 300, Exploration rate: 0.9674368933056677\n",
            "Episode: 400, Exploration rate: 0.9574324499695593\n",
            "Episode: 500, Exploration rate: 0.9469915240401379\n",
            "Episode: 600, Exploration rate: 0.9379813995623048\n",
            "Episode: 700, Exploration rate: 0.9280309581043615\n",
            "Episode: 800, Exploration rate: 0.9183284047084567\n",
            "Episode: 900, Exploration rate: 0.9083002888599128\n",
            "Episode: 1000, Exploration rate: 0.8988175015877022\n",
            "Episode: 1100, Exploration rate: 0.8896649994052988\n",
            "Episode: 1200, Exploration rate: 0.8809315807667751\n",
            "Episode: 1300, Exploration rate: 0.8722751711328363\n",
            "Episode: 1400, Exploration rate: 0.8636951860572823\n",
            "Episode: 1500, Exploration rate: 0.8548917793190901\n",
            "Episode: 1600, Exploration rate: 0.8467071312180565\n",
            "Episode: 1700, Exploration rate: 0.8389782983604366\n",
            "Episode: 1800, Exploration rate: 0.8304434327832453\n",
            "Episode: 1900, Exploration rate: 0.8225257511526715\n",
            "Episode: 2000, Exploration rate: 0.8144106849637481\n",
            "Episode: 2100, Exploration rate: 0.8068677227388714\n",
            "Episode: 2200, Exploration rate: 0.7991748185693226\n",
            "Episode: 2300, Exploration rate: 0.7902779275000796\n",
            "Episode: 2400, Exploration rate: 0.7827549363771525\n",
            "Episode: 2500, Exploration rate: 0.7748656359198328\n",
            "Episode: 2600, Exploration rate: 0.767151739063497\n",
            "Episode: 2700, Exploration rate: 0.7596133787075827\n",
            "Episode: 2800, Exploration rate: 0.7524086303510193\n",
            "Episode: 2900, Exploration rate: 0.7446427266821944\n",
            "Episode: 3000, Exploration rate: 0.7366990874880878\n",
            "Episode: 3100, Exploration rate: 0.7287199397919747\n",
            "Episode: 3200, Exploration rate: 0.7210723373441615\n",
            "Episode: 3300, Exploration rate: 0.7137262145843654\n",
            "Episode: 3400, Exploration rate: 0.7063454401682634\n",
            "Episode: 3500, Exploration rate: 0.6988417929081628\n",
            "Episode: 3600, Exploration rate: 0.6908269472807264\n",
            "Episode: 3700, Exploration rate: 0.6836658865075366\n",
            "Episode: 3800, Exploration rate: 0.6761698492033137\n",
            "Episode: 3900, Exploration rate: 0.6688730448442428\n",
            "Episode: 4000, Exploration rate: 0.6619561053286054\n",
            "Episode: 4100, Exploration rate: 0.6542726878144606\n",
            "Episode: 4200, Exploration rate: 0.6472413092750121\n",
            "Episode: 4300, Exploration rate: 0.6406185318654485\n",
            "Episode: 4400, Exploration rate: 0.6330466625591281\n",
            "Episode: 4500, Exploration rate: 0.6257363441569609\n",
            "Episode: 4600, Exploration rate: 0.6192592965793342\n",
            "Episode: 4700, Exploration rate: 0.6126470860394665\n",
            "Episode: 4800, Exploration rate: 0.6060842647451411\n",
            "Episode: 4900, Exploration rate: 0.5999906080685564\n",
            "Episode: 5000, Exploration rate: 0.5940948443187329\n",
            "Episode: 5100, Exploration rate: 0.587583844358134\n",
            "Episode: 5200, Exploration rate: 0.5808972674676937\n",
            "Episode: 5300, Exploration rate: 0.5743901635574007\n",
            "Episode: 5400, Exploration rate: 0.5681206825459243\n",
            "Episode: 5500, Exploration rate: 0.5617988330181378\n",
            "Episode: 5600, Exploration rate: 0.5547423689312855\n",
            "Episode: 5700, Exploration rate: 0.5488190451168179\n",
            "Episode: 5800, Exploration rate: 0.5426468558101085\n",
            "Episode: 5900, Exploration rate: 0.5368795265648899\n",
            "Episode: 6000, Exploration rate: 0.5314125757880188\n",
            "Episode: 6100, Exploration rate: 0.5255806602085551\n",
            "Episode: 6200, Exploration rate: 0.5196724153526066\n",
            "Episode: 6300, Exploration rate: 0.513871695436835\n",
            "Episode: 6400, Exploration rate: 0.507904574937423\n",
            "Episode: 6500, Exploration rate: 0.5022226549907518\n",
            "Episode: 6600, Exploration rate: 0.4962419088314728\n",
            "Episode: 6700, Exploration rate: 0.49095795879054893\n",
            "Episode: 6800, Exploration rate: 0.4849658469430839\n",
            "Episode: 6900, Exploration rate: 0.4799459261833152\n",
            "Episode: 7000, Exploration rate: 0.47441545008978553\n",
            "Episode: 7100, Exploration rate: 0.468723660428937\n",
            "Episode: 7200, Exploration rate: 0.46319973538523984\n",
            "Episode: 7300, Exploration rate: 0.45794007110321094\n",
            "Episode: 7400, Exploration rate: 0.4524074880978366\n",
            "Episode: 7500, Exploration rate: 0.44642582574728107\n",
            "Episode: 7600, Exploration rate: 0.4409375395952501\n",
            "Episode: 7700, Exploration rate: 0.43495309499723256\n",
            "Episode: 7800, Exploration rate: 0.42917646052797426\n",
            "Episode: 7900, Exploration rate: 0.4238663245061088\n",
            "Episode: 8000, Exploration rate: 0.41817420301509595\n",
            "Episode: 8100, Exploration rate: 0.41289076545107084\n",
            "Episode: 8200, Exploration rate: 0.407085416569275\n",
            "Episode: 8300, Exploration rate: 0.40100062844248685\n",
            "Episode: 8400, Exploration rate: 0.3960470286492359\n",
            "Episode: 8500, Exploration rate: 0.39042384367775707\n",
            "Episode: 8600, Exploration rate: 0.38516926760836967\n",
            "Episode: 8700, Exploration rate: 0.38007281792951253\n",
            "Episode: 8800, Exploration rate: 0.3749988003477341\n",
            "Episode: 8900, Exploration rate: 0.3693400590434848\n",
            "Episode: 9000, Exploration rate: 0.3633885866228892\n",
            "Episode: 9100, Exploration rate: 0.3585803326905485\n",
            "Episode: 9200, Exploration rate: 0.35292221382126376\n",
            "Episode: 9300, Exploration rate: 0.34721446175587684\n",
            "Episode: 9400, Exploration rate: 0.342197343373337\n",
            "Episode: 9500, Exploration rate: 0.3375260065171532\n",
            "Episode: 9600, Exploration rate: 0.33303664541457806\n",
            "Episode: 9700, Exploration rate: 0.3285971382555818\n",
            "Episode: 9800, Exploration rate: 0.32354637510753254\n",
            "Episode: 9900, Exploration rate: 0.3189701173338952\n",
            "Episode: 10000, Exploration rate: 0.31414428420772345\n",
            "Episode: 10100, Exploration rate: 0.3094548950516785\n",
            "Episode: 10200, Exploration rate: 0.30500473784414944\n",
            "Episode: 10300, Exploration rate: 0.30043375266571304\n",
            "Episode: 10400, Exploration rate: 0.2959135156433671\n",
            "Episode: 10500, Exploration rate: 0.2915297903876177\n",
            "Episode: 10600, Exploration rate: 0.2864996039917486\n",
            "Episode: 10700, Exploration rate: 0.2816716727021964\n",
            "Episode: 10800, Exploration rate: 0.2774781174214087\n",
            "Episode: 10900, Exploration rate: 0.2734563571424504\n",
            "Episode: 11000, Exploration rate: 0.2696451950326891\n",
            "Episode: 11100, Exploration rate: 0.2653625388933433\n",
            "Episode: 11200, Exploration rate: 0.2610278015894507\n",
            "Episode: 11300, Exploration rate: 0.25714159427124084\n",
            "Episode: 11400, Exploration rate: 0.25298541602896524\n",
            "Episode: 11500, Exploration rate: 0.24889641407386456\n",
            "Episode: 11600, Exploration rate: 0.2447890356377792\n",
            "Episode: 11700, Exploration rate: 0.2410590012967146\n",
            "Episode: 11800, Exploration rate: 0.23715565112646428\n",
            "Episode: 11900, Exploration rate: 0.23346370875716568\n",
            "Episode: 12000, Exploration rate: 0.2293677470682004\n",
            "Episode: 12100, Exploration rate: 0.22564016879305793\n",
            "Episode: 12200, Exploration rate: 0.22190547772929847\n",
            "Episode: 12300, Exploration rate: 0.21801556754514997\n",
            "Episode: 12400, Exploration rate: 0.2146849130510992\n",
            "Episode: 12500, Exploration rate: 0.21135441016150666\n",
            "Episode: 12600, Exploration rate: 0.20796428391215394\n",
            "Episode: 12700, Exploration rate: 0.2044485409601357\n",
            "Episode: 12800, Exploration rate: 0.20102137950684243\n",
            "Episode: 12900, Exploration rate: 0.19738205625420355\n",
            "Episode: 13000, Exploration rate: 0.19424906627844168\n",
            "Episode: 13100, Exploration rate: 0.1908229696825139\n",
            "Episode: 13200, Exploration rate: 0.18753417481503648\n",
            "Episode: 13300, Exploration rate: 0.18442281935079255\n",
            "Episode: 13400, Exploration rate: 0.1814202224995204\n",
            "Episode: 13500, Exploration rate: 0.178412979016022\n",
            "Episode: 13600, Exploration rate: 0.17466169241480728\n",
            "Episode: 13700, Exploration rate: 0.17155619350451132\n",
            "Episode: 13800, Exploration rate: 0.16890743330764646\n",
            "Episode: 13900, Exploration rate: 0.16622391964564617\n",
            "Episode: 14000, Exploration rate: 0.16327171042215793\n",
            "Episode: 14100, Exploration rate: 0.16084975181989578\n",
            "Episode: 14200, Exploration rate: 0.15773645939545053\n",
            "Episode: 14300, Exploration rate: 0.1552886468415829\n",
            "Episode: 14400, Exploration rate: 0.15254438123757127\n",
            "Episode: 14500, Exploration rate: 0.14981340200270546\n",
            "Episode: 14600, Exploration rate: 0.147249803770657\n",
            "Episode: 14700, Exploration rate: 0.14473586301583577\n",
            "Episode: 14800, Exploration rate: 0.14196710822692882\n",
            "Episode: 14900, Exploration rate: 0.13948197123008485\n",
            "Episode: 15000, Exploration rate: 0.13618922713881149\n",
            "Episode: 15100, Exploration rate: 0.1328346646989513\n",
            "Episode: 15200, Exploration rate: 0.1301984965179832\n",
            "Episode: 15300, Exploration rate: 0.12739852022427672\n",
            "Episode: 15400, Exploration rate: 0.12503454774192738\n",
            "Episode: 15500, Exploration rate: 0.12289496382452553\n",
            "Episode: 15600, Exploration rate: 0.1206296359164039\n",
            "Episode: 15700, Exploration rate: 0.1182954066839679\n",
            "Episode: 15800, Exploration rate: 0.11583304532724296\n",
            "Episode: 15900, Exploration rate: 0.11367344757258539\n",
            "Episode: 16000, Exploration rate: 0.1118009213088695\n",
            "Episode: 16100, Exploration rate: 0.10973899294324693\n",
            "Episode: 16200, Exploration rate: 0.10765425043705969\n",
            "Episode: 16300, Exploration rate: 0.10473880067073935\n",
            "Episode: 16400, Exploration rate: 0.10192931371709052\n",
            "Episode: 16500, Exploration rate: 0.09976670562255117\n",
            "Episode: 16600, Exploration rate: 0.09793602607560285\n",
            "Episode: 16700, Exploration rate: 0.09611202357166844\n",
            "Episode: 16800, Exploration rate: 0.0940907150117617\n",
            "Episode: 16900, Exploration rate: 0.09228894131119132\n",
            "Episode: 17000, Exploration rate: 0.09079046607850223\n",
            "Episode: 17100, Exploration rate: 0.08915391298408737\n",
            "Episode: 17200, Exploration rate: 0.08760334583014272\n",
            "Episode: 17300, Exploration rate: 0.08604230954000922\n",
            "Episode: 17400, Exploration rate: 0.08445628811964787\n",
            "Episode: 17500, Exploration rate: 0.08289287018571177\n",
            "Episode: 17600, Exploration rate: 0.08125635256710834\n",
            "Episode: 17700, Exploration rate: 0.07985631522558144\n",
            "Episode: 17800, Exploration rate: 0.07832712067562034\n",
            "Episode: 17900, Exploration rate: 0.07676538799782383\n",
            "Episode: 18000, Exploration rate: 0.0751314170619026\n",
            "Episode: 18100, Exploration rate: 0.07364407986592506\n",
            "Episode: 18200, Exploration rate: 0.07240850141669265\n",
            "Episode: 18300, Exploration rate: 0.07105318407760657\n",
            "Episode: 18400, Exploration rate: 0.06968211042216291\n",
            "Episode: 18500, Exploration rate: 0.06818254304773463\n",
            "Episode: 18600, Exploration rate: 0.06635927216466435\n",
            "Episode: 18700, Exploration rate: 0.06451891437686513\n",
            "Episode: 18800, Exploration rate: 0.06280837093855254\n",
            "Episode: 18900, Exploration rate: 0.060282886482394195\n",
            "Episode: 19000, Exploration rate: 0.05857852638535018\n",
            "Episode: 19100, Exploration rate: 0.057364929550147395\n",
            "Episode: 19200, Exploration rate: 0.05615260534000073\n",
            "Episode: 19300, Exploration rate: 0.054231829311022654\n",
            "Episode: 19400, Exploration rate: 0.052036109414854134\n",
            "Episode: 19500, Exploration rate: 0.05042201123734019\n",
            "Episode: 19600, Exploration rate: 0.048978319353031145\n",
            "Episode: 19700, Exploration rate: 0.04768289179588447\n",
            "Episode: 19800, Exploration rate: 0.04598579665307411\n",
            "Episode: 19900, Exploration rate: 0.04504187121292921\n",
            "Episode: 20000, Exploration rate: 0.04411290969440278\n",
            "Episode: 20100, Exploration rate: 0.04292255339953439\n",
            "Episode: 20200, Exploration rate: 0.04160612242786118\n",
            "Episode: 20300, Exploration rate: 0.04070159477063411\n",
            "Episode: 20400, Exploration rate: 0.03978986448177297\n",
            "Episode: 20500, Exploration rate: 0.0385163234546125\n",
            "Episode: 20600, Exploration rate: 0.03760913893647147\n",
            "Episode: 20700, Exploration rate: 0.03638501430508702\n",
            "Episode: 20800, Exploration rate: 0.03524158985549256\n",
            "Episode: 20900, Exploration rate: 0.03416056256258258\n",
            "Episode: 21000, Exploration rate: 0.03296583586054378\n",
            "Episode: 21100, Exploration rate: 0.03192443384945935\n",
            "Episode: 21200, Exploration rate: 0.030893678569710904\n",
            "Episode: 21300, Exploration rate: 0.02995365963829484\n",
            "Episode: 21400, Exploration rate: 0.029116541171705045\n",
            "Episode: 21500, Exploration rate: 0.02850206054553008\n",
            "Episode: 21600, Exploration rate: 0.02796325527663224\n",
            "Episode: 21700, Exploration rate: 0.02740899616623205\n",
            "Episode: 21800, Exploration rate: 0.026875530817547816\n",
            "Episode: 21900, Exploration rate: 0.026327688659406764\n",
            "Episode: 22000, Exploration rate: 0.025828308994508477\n",
            "Episode: 22100, Exploration rate: 0.02532332958625216\n",
            "Episode: 22200, Exploration rate: 0.02480650798083338\n",
            "Episode: 22300, Exploration rate: 0.024392750933694442\n",
            "Episode: 22400, Exploration rate: 0.023934739709360126\n",
            "Episode: 22500, Exploration rate: 0.023475466555168054\n",
            "Episode: 22600, Exploration rate: 0.022981415010761737\n",
            "Episode: 22700, Exploration rate: 0.02247752207233015\n",
            "Episode: 22800, Exploration rate: 0.022042132642125782\n",
            "Episode: 22900, Exploration rate: 0.021502101615994456\n",
            "Episode: 23000, Exploration rate: 0.02100888874888385\n",
            "Episode: 23100, Exploration rate: 0.02043686857795236\n",
            "Episode: 23200, Exploration rate: 0.019963996861242343\n",
            "Episode: 23300, Exploration rate: 0.01950304166031875\n",
            "Episode: 23400, Exploration rate: 0.01895182748933762\n",
            "Episode: 23500, Exploration rate: 0.018534897540567554\n",
            "Episode: 23600, Exploration rate: 0.01812061521289595\n",
            "Episode: 23700, Exploration rate: 0.01758199165414507\n",
            "Episode: 23800, Exploration rate: 0.017079349535509925\n",
            "Episode: 23900, Exploration rate: 0.01655635517300946\n",
            "Episode: 24000, Exploration rate: 0.015980031921201343\n",
            "Episode: 24100, Exploration rate: 0.015393954147238258\n",
            "Episode: 24200, Exploration rate: 0.014876901260295337\n",
            "Episode: 24300, Exploration rate: 0.014347198095099958\n",
            "Episode: 24400, Exploration rate: 0.013908352942724847\n",
            "Episode: 24500, Exploration rate: 0.013464606604962709\n",
            "Episode: 24600, Exploration rate: 0.01309184398214234\n",
            "Episode: 24700, Exploration rate: 0.012735640104386863\n",
            "Episode: 24800, Exploration rate: 0.012398051254983701\n",
            "Episode: 24900, Exploration rate: 0.01206078444595987\n",
            "Episode: 25000, Exploration rate: 0.011728234789982177\n",
            "Episode: 25100, Exploration rate: 0.011396474951644087\n",
            "Episode: 25200, Exploration rate: 0.011086620532992517\n",
            "Episode: 25300, Exploration rate: 0.01080364912780337\n",
            "Episode: 25400, Exploration rate: 0.010527215902512746\n",
            "Episode: 25500, Exploration rate: 0.01021430122348372\n",
            "Episode: 25600, Exploration rate: 0.009850514904275647\n",
            "Episode: 25700, Exploration rate: 0.00953742609422198\n",
            "Episode: 25800, Exploration rate: 0.009266711550770463\n",
            "Episode: 25900, Exploration rate: 0.008928991752080666\n",
            "Episode: 26000, Exploration rate: 0.008633874822181508\n",
            "Episode: 26100, Exploration rate: 0.00838335611336199\n",
            "Episode: 26200, Exploration rate: 0.00815106223973177\n",
            "Episode: 26300, Exploration rate: 0.007912653450498828\n",
            "Episode: 26400, Exploration rate: 0.00767948974834454\n",
            "Episode: 26500, Exploration rate: 0.007462071332101541\n",
            "Episode: 26600, Exploration rate: 0.0072009858848266824\n",
            "Episode: 26700, Exploration rate: 0.00698788454328949\n",
            "Episode: 26800, Exploration rate: 0.006732575614759312\n",
            "Episode: 26900, Exploration rate: 0.006497078978232172\n",
            "Episode: 27000, Exploration rate: 0.006266810905382344\n",
            "Episode: 27100, Exploration rate: 0.005993811296710247\n",
            "Episode: 27200, Exploration rate: 0.005654051345387797\n",
            "Episode: 27300, Exploration rate: 0.00539831692680755\n",
            "Episode: 27400, Exploration rate: 0.005102762623768403\n",
            "Episode: 27500, Exploration rate: 0.004894376924676637\n",
            "Episode: 27600, Exploration rate: 0.0046991511123161975\n",
            "Episode: 27700, Exploration rate: 0.004402452248821215\n",
            "Episode: 27800, Exploration rate: 0.0041837860391653325\n",
            "Episode: 27900, Exploration rate: 0.004003069641555933\n",
            "Episode: 28000, Exploration rate: 0.00379252241330028\n",
            "Episode: 28100, Exploration rate: 0.0036406099632218447\n",
            "Episode: 28200, Exploration rate: 0.00348494105681342\n",
            "Episode: 28300, Exploration rate: 0.0033048992808535913\n",
            "Episode: 28400, Exploration rate: 0.003184693033059564\n",
            "Episode: 28500, Exploration rate: 0.0030767406902327482\n",
            "Episode: 28600, Exploration rate: 0.002965351950326767\n",
            "Episode: 28700, Exploration rate: 0.0028336499438047884\n",
            "Episode: 28800, Exploration rate: 0.002699753553719689\n",
            "Episode: 28900, Exploration rate: 0.002532711157579412\n",
            "Episode: 29000, Exploration rate: 0.002405626104210107\n",
            "Episode: 29100, Exploration rate: 0.0022702842849303875\n",
            "Episode: 29200, Exploration rate: 0.0021644146165227802\n",
            "Episode: 29300, Exploration rate: 0.00205710532545591\n",
            "Episode: 29400, Exploration rate: 0.0019540803710774166\n",
            "Episode: 29500, Exploration rate: 0.0018504420344710119\n",
            "Episode: 29600, Exploration rate: 0.0017680803928937512\n",
            "Episode: 29700, Exploration rate: 0.0017250212558470104\n",
            "Episode: 29800, Exploration rate: 0.0016893339188292782\n",
            "Episode: 29900, Exploration rate: 0.0016460842004556895\n",
            "Episode: 30000, Exploration rate: 0.0016038936281394277\n",
            "Episode: 30100, Exploration rate: 0.0015586251507407644\n",
            "Episode: 30200, Exploration rate: 0.001508972624460529\n",
            "Episode: 30300, Exploration rate: 0.001470730143792379\n",
            "Episode: 30400, Exploration rate: 0.0014358886329998762\n",
            "Episode: 30500, Exploration rate: 0.0013909108696525487\n",
            "Episode: 30600, Exploration rate: 0.0013307912950115252\n",
            "Episode: 30700, Exploration rate: 0.0012759342032386354\n",
            "Episode: 30800, Exploration rate: 0.0012250461502768953\n",
            "Episode: 30900, Exploration rate: 0.001174794703927808\n",
            "Episode: 31000, Exploration rate: 0.001128442441598423\n",
            "Episode: 31100, Exploration rate: 0.0010786963178841434\n",
            "Episode: 31200, Exploration rate: 0.0010300919639610337\n",
            "Episode: 31300, Exploration rate: 0.0010041767182303579\n",
            "Episode: 31400, Exploration rate: 0.000979114151415207\n",
            "Episode: 31500, Exploration rate: 0.0009567701433683536\n",
            "Episode: 31600, Exploration rate: 0.000933665387853333\n",
            "Episode: 31700, Exploration rate: 0.0009088299923088038\n",
            "Episode: 31800, Exploration rate: 0.0008792576455235701\n",
            "Episode: 31900, Exploration rate: 0.0008397278504827328\n",
            "Episode: 32000, Exploration rate: 0.0008145149442299737\n",
            "Episode: 32100, Exploration rate: 0.0007890089751033393\n",
            "Episode: 32200, Exploration rate: 0.0007653763089814238\n",
            "Episode: 32300, Exploration rate: 0.0007441573837474591\n",
            "Episode: 32400, Exploration rate: 0.0007230240441790918\n",
            "Episode: 32500, Exploration rate: 0.0007038655871560105\n",
            "Episode: 32600, Exploration rate: 0.0006829402234321099\n",
            "Episode: 32700, Exploration rate: 0.0006613857499070827\n",
            "Episode: 32800, Exploration rate: 0.0006483963790324036\n",
            "Episode: 32900, Exploration rate: 0.0006329377936592125\n",
            "Episode: 33000, Exploration rate: 0.0006155505529631416\n",
            "Episode: 33100, Exploration rate: 0.0005977137747970138\n",
            "Episode: 33200, Exploration rate: 0.0005779786428862817\n",
            "Episode: 33300, Exploration rate: 0.0005595438156995427\n",
            "Episode: 33400, Exploration rate: 0.0005411690751763247\n",
            "Episode: 33500, Exploration rate: 0.0005233480183068451\n",
            "Episode: 33600, Exploration rate: 0.0005046583061741601\n",
            "Episode: 33700, Exploration rate: 0.0004866019743294933\n",
            "Episode: 33800, Exploration rate: 0.000472428500522484\n",
            "Episode: 33900, Exploration rate: 0.00045520657231053896\n",
            "Episode: 34000, Exploration rate: 0.00043774266863900774\n",
            "Episode: 34100, Exploration rate: 0.0004172356221075953\n",
            "Episode: 34200, Exploration rate: 0.00040152548558419093\n",
            "Episode: 34300, Exploration rate: 0.000385764047705286\n",
            "Episode: 34400, Exploration rate: 0.00037029345202069637\n",
            "Episode: 34500, Exploration rate: 0.00035247710915755996\n",
            "Episode: 34600, Exploration rate: 0.0003380573572722422\n",
            "Episode: 34700, Exploration rate: 0.00032578429308479886\n",
            "Episode: 34800, Exploration rate: 0.0003132496218583577\n",
            "Episode: 34900, Exploration rate: 0.0002995976102727914\n",
            "Episode: 35000, Exploration rate: 0.00028816267889274894\n",
            "Episode: 35100, Exploration rate: 0.0002792228194611228\n",
            "Episode: 35200, Exploration rate: 0.0002669816653835572\n",
            "Episode: 35300, Exploration rate: 0.0002589020772883495\n",
            "Episode: 35400, Exploration rate: 0.0002503937870214685\n",
            "Episode: 35500, Exploration rate: 0.00024163896637683087\n",
            "Episode: 35600, Exploration rate: 0.0002311078827351969\n",
            "Episode: 35700, Exploration rate: 0.0002210081358440601\n",
            "Episode: 35800, Exploration rate: 0.00021260360397913394\n",
            "Episode: 35900, Exploration rate: 0.00020464552217900437\n",
            "Episode: 36000, Exploration rate: 0.0001965268810347939\n",
            "Episode: 36100, Exploration rate: 0.00018702907709886618\n",
            "Episode: 36200, Exploration rate: 0.00018091530872861255\n",
            "Episode: 36300, Exploration rate: 0.00017265819650503594\n",
            "Episode: 36400, Exploration rate: 0.00016552442912164028\n",
            "Episode: 36500, Exploration rate: 0.0001594385686106716\n",
            "Episode: 36600, Exploration rate: 0.0001527333500568544\n",
            "Episode: 36700, Exploration rate: 0.00014715677246658274\n",
            "Episode: 36800, Exploration rate: 0.00014161447518002662\n",
            "Episode: 36900, Exploration rate: 0.00013660155241937443\n",
            "Episode: 37000, Exploration rate: 0.00013199819207374014\n",
            "Episode: 37100, Exploration rate: 0.00012732630677154874\n",
            "Episode: 37200, Exploration rate: 0.00012125284746693796\n",
            "Episode: 37300, Exploration rate: 0.00011575986289177567\n",
            "Episode: 37400, Exploration rate: 0.00011044004342826314\n",
            "Episode: 37500, Exploration rate: 0.0001051310489440528\n",
            "Episode: 37600, Exploration rate: 0.00010168426525115546\n",
            "Episode: 37700, Exploration rate: 9.844248734116576e-05\n",
            "Episode: 37800, Exploration rate: 9.56439479188766e-05\n",
            "Episode: 37900, Exploration rate: 9.175181941057534e-05\n",
            "Episode: 38000, Exploration rate: 8.817488901339196e-05\n",
            "Episode: 38100, Exploration rate: 8.571836929277653e-05\n",
            "Episode: 38200, Exploration rate: 8.262456677369288e-05\n",
            "Episode: 38300, Exploration rate: 8.040344204303761e-05\n",
            "Episode: 38400, Exploration rate: 7.761470436659353e-05\n",
            "Episode: 38500, Exploration rate: 7.466092041501648e-05\n",
            "Episode: 38600, Exploration rate: 7.241342606493081e-05\n",
            "Episode: 38700, Exploration rate: 7.032881858827497e-05\n",
            "Episode: 38800, Exploration rate: 6.800468283642978e-05\n",
            "Episode: 38900, Exploration rate: 6.627127222365069e-05\n",
            "Episode: 39000, Exploration rate: 6.383370930355496e-05\n",
            "Episode: 39100, Exploration rate: 6.145168859057854e-05\n",
            "Episode: 39200, Exploration rate: 5.902559798887056e-05\n",
            "Episode: 39300, Exploration rate: 5.6861365476378785e-05\n",
            "Episode: 39400, Exploration rate: 5.502106095522388e-05\n",
            "Episode: 39500, Exploration rate: 5.295677118888223e-05\n",
            "Episode: 39600, Exploration rate: 5.1580612594245165e-05\n",
            "Episode: 39700, Exploration rate: 5.010550109856571e-05\n",
            "Episode: 39800, Exploration rate: 4.89084774274197e-05\n",
            "Episode: 39900, Exploration rate: 4.7193947562727935e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now let's test the learned algorithm\n",
        "## We want to try and get the pole to balance for 120 frames\n",
        "## Maybe try and update the hyperparameters for the algorith to achieve this"
      ],
      "metadata": {
        "id": "W0-olF6SnlOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames = []\n",
        "env.close()  # Close the previous env\n",
        "env = gym.make('CartPole-v1')  # Re-make the environment\n",
        "\n",
        "state = discretize_state(env.reset(), state_space)\n",
        "state = np.prod(state)\n",
        "img = plt.imshow(env.render(mode='rgb_array')) # only call this once, only for the first frame\n",
        "done = False\n",
        "while not done:\n",
        "    frame = env.render(mode='rgb_array')\n",
        "    frames.append(frame)\n",
        "    action = agent.choose_action(state)\n",
        "    next_state, reward, done, info = env.step(action)\n",
        "    state = discretize_state(next_state, state_space)\n",
        "    state = np.prod(state)\n",
        "\n",
        "env.close()\n",
        "\n",
        "# Save frames as video\n",
        "imageio.mimsave('cartpole-v1.gif', frames, 'GIF', fps=30)\n"
      ],
      "metadata": {
        "id": "43Sa3JQyJp5Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "a5b0764f-c110-4748-b231-02a53bbc3fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}